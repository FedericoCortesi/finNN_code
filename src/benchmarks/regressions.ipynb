{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86a78022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "206f8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pipeline.walkforward import WFCVGenerator\n",
    "from config.config_types import AppConfig\n",
    "from utils.paths import CONFIG_DIR, VOL_EXPERIMENTS_DIR, DATA_DIR, PRICE_EXPERIMENTS_DIR\n",
    "from models import create_model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d5938",
   "metadata": {},
   "source": [
    "## OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4e5421a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentConfig(name='mlp_40', hyperparams_search=False, monitor='val_loss', mode='min', type='price_prediction', n_trials=10, random_state=42)\n",
      "WFConfig(target_col='ret', lookback=0, ratio_train=3, ratio_val=1, ratio_test=1, step=251, lags=40, max_folds=None, scale=True, clip=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fix a fold\n",
    "fold_num = 0\n",
    "name = \"exp_003_mlp_60_windows\"\n",
    "name = \"exp_007_mlp_40_sliding\"\n",
    "name  = \"exp_007_mlp_40_sliding\"\n",
    "\n",
    "name  = \"exp_011_mlp_40\"\n",
    "trial = \"trial_20251029_182517\" \n",
    "\n",
    "\n",
    "# -------- load config --------\n",
    "base = f\"{PRICE_EXPERIMENTS_DIR}/{name}/{trial}/\"\n",
    "\n",
    "conifg_path = f\"{base}config_snapshot.json\"\n",
    "\n",
    "with open(conifg_path, 'r') as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "cfg = cfg[\"cfg\"]\n",
    "\n",
    "cfg = AppConfig.from_dict(cfg)\n",
    "\n",
    "print(cfg.experiment)\n",
    "print(cfg.walkforward)\n",
    "\n",
    "if cfg.data[\"df_master\"] is not None:\n",
    "    df_master_path =  cfg.data[\"df_master\"]\n",
    "    df_master = pd.read_parquet(f\"{DATA_DIR}/{df_master_path}\")\n",
    "    #print(f\"provided df master: {df_master_path}\\n{df_master.head()}\")\n",
    "else:\n",
    "    df_master = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92417dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wf = WFCVGenerator(config=cfg.walkforward)\n",
    "test_data = {}\n",
    "data = {}\n",
    "for i, fold_data in enumerate(wf.folds()):\n",
    "\n",
    "    X_test = fold_data[4]\n",
    "    y_test = fold_data[5]\n",
    "\n",
    "    test_data[i] = [X_test, y_test]\n",
    "    data[i] = fold_data\n",
    "    if i == fold_num:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c67a1762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000, 1.0000, -25.3492, 26.4821\n",
      "0.0000, 1.0000, -25.3237, 26.4271\n",
      "0.0421, 0.6408, -10.8975, 15.6728\n",
      "0.0521, 0.6180, -10.8754, 15.6401\n",
      "0.0106, 0.5195, -10.7222, 9.6848\n",
      "0.0091, 0.5099, -10.7004, 7.2176\n"
     ]
    }
   ],
   "source": [
    "X_tr, y_tr, X_val, y_val, X_test, y_test = data[fold_num] \n",
    "\n",
    "for arr in data[fold_num]:\n",
    "    print(f\"{np.mean(arr):.4f}, {np.std(arr):.4f}, {np.min(arr):.4f}, {np.max(arr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d165009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Target 0 ===\n",
      "Rsq: 0.00719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "X_tr_const = sm.add_constant(X_tr)\n",
    "X_te_const = sm.add_constant(X_test)\n",
    "results = []\n",
    "for j in range(y_tr.shape[1]):\n",
    "    res = sm.OLS(y_tr[:, j].squeeze(), X_tr_const).fit()\n",
    "    results.append(res)\n",
    "    print(f\"\\n=== Target {j} ===\")\n",
    "    print(f\"Rsq: {res.rsquared:.5f}\")\n",
    "    #print(res.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e49ee3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim: 0\n",
      "Model\tTrain MSE\tTrain Acc\tTest MSE\tTest Acc\n",
      "OLS\t0.99281, \t52.00%, \t0.26191, \t49.57%\n",
      "MLP\t0.48345, \t65.20%, \t0.30437, \t50.72%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "hparams = cfg.model.hparams\n",
    "input_shape = (cfg.walkforward.lags,)\n",
    "output_shape = cfg.walkforward.lookback+1\n",
    "ckpt_path = f\"{base}fold_{fold_num:03d}/model_best.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cuda\")\n",
    "state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in checkpoint[\"model_state\"].items()}\n",
    "model = create_model(cfg.model, input_shape, output_shape)\n",
    "model.load_state_dict(state_dict)         \n",
    "model.to(\"cuda\").eval()\n",
    "\n",
    "y_pred_test_nn = model(torch.as_tensor(X_test, dtype=torch.float32, device=\"cuda\")).cpu().detach()\n",
    "y_pred_train_nn = model(torch.as_tensor(X_tr, dtype=torch.float32, device=\"cuda\")).cpu().detach()\n",
    "y_pred_test_nn = y_pred_test_nn.cpu().numpy()\n",
    "y_pred_train_nn = y_pred_train_nn.cpu().numpy()\n",
    "\n",
    "i = 0\n",
    "for dim in range(y_test.shape[1]):\n",
    "\n",
    "    y_te_dim = y_test[:,dim]\n",
    "    y_tr_dim = y_tr[:,dim]\n",
    "    y_pred_test_ols = results[dim].predict(X_te_const)\n",
    "    y_pred_tr_ols = results[dim].predict(X_tr_const)\n",
    "    y_pred_test_nn_dim = y_pred_test_nn[:,dim]\n",
    "    y_pred_train_nn_dim = y_pred_train_nn[:,dim]\n",
    "\n",
    "\n",
    "\n",
    "    mse_test_ols = np.mean((y_te_dim - y_pred_test_ols)**2)\n",
    "    mse_test_nn  = np.mean((y_te_dim - y_pred_test_nn_dim)**2)\n",
    "    mse_tr_ols = np.mean((y_tr_dim - y_pred_tr_ols)**2)\n",
    "    mse_tr_nn  = np.mean((y_tr_dim - y_pred_train_nn_dim)**2)\n",
    "\n",
    "    dir_acc_test_ols = np.mean(np.sign(y_te_dim) == np.sign(y_pred_test_ols)) * 100\n",
    "    dir_acc_test_nn = np.mean(np.sign(y_te_dim) == np.sign(y_pred_test_nn_dim)) * 100\n",
    "    \n",
    "    # Train set\n",
    "    dir_acc_tr_ols = np.mean(np.sign(y_tr_dim) == np.sign(y_pred_tr_ols)) * 100\n",
    "    dir_acc_tr_nn = np.mean(np.sign(y_tr_dim) == np.sign(y_pred_train_nn_dim)) * 100\n",
    "\n",
    "    print(f'Dim: {i}')\n",
    "    print(\"Model\\tTrain MSE\\tTrain Acc\\tTest MSE\\tTest Acc\")\n",
    "    print(f\"OLS\\t{mse_tr_ols:.5f}, \\t{dir_acc_tr_ols:.2f}%, \\t{mse_test_ols:.5f}, \\t{dir_acc_test_ols:.2f}%\")\n",
    "    print(f\"MLP\\t{mse_tr_nn:.5f}, \\t{dir_acc_tr_nn:.2f}%, \\t{mse_test_nn:.5f}, \\t{dir_acc_test_nn:.2f}%\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e791db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a577bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#plt.figure(figsize=(12,8))\n",
    "#sns.scatterplot(x=y_test_dim, y=y_pred_ols, s=25, alpha=0.6, edgecolor=None)\n",
    "#plt.xlabel(\"True\")\n",
    "#plt.ylabel(\"Predicted\")\n",
    "#plt.legend()\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3681d22",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9660968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² train: 0.0072, R² test: -0.0073, RMSE test: 0.511771\n",
      "const     0.000000\n",
      "x0       -0.003493\n",
      "x1        0.003752\n",
      "x2       -0.007206\n",
      "x3       -0.014402\n",
      "x4       -0.006406\n",
      "x5       -0.001036\n",
      "x6       -0.028039\n",
      "x7       -0.027452\n",
      "x8       -0.017108\n",
      "x9       -0.010208\n",
      "x10      -0.010113\n",
      "x11       0.019849\n",
      "x12      -0.000167\n",
      "x13       0.001001\n",
      "x14       0.006934\n",
      "x15      -0.009141\n",
      "x16       0.013288\n",
      "x17       0.003159\n",
      "x18      -0.005657\n",
      "x19      -0.008736\n",
      "x20      -0.012195\n",
      "x21      -0.023765\n",
      "x22      -0.014709\n",
      "x23      -0.000548\n",
      "x24       0.018021\n",
      "x25      -0.001526\n",
      "x26      -0.010829\n",
      "x27       0.014869\n",
      "x28       0.010282\n",
      "x29      -0.003309\n",
      "x30      -0.017251\n",
      "x31       0.004291\n",
      "x32      -0.010054\n",
      "x33       0.003491\n",
      "x34      -0.016074\n",
      "x35      -0.010637\n",
      "x36      -0.000879\n",
      "x37       0.000836\n",
      "x38      -0.036394\n",
      "x39       0.006292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# fix a fold\n",
    "fold = 0\n",
    "\n",
    "X_tr, y_tr, X_val, y_val, X_test, y_test = data[fold] \n",
    "\n",
    "X_tr_const = sm.add_constant(X_tr)\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "# --- Define ridge regression (alpha = λ penalty strength) ---\n",
    "ridge = Ridge(alpha=2, fit_intercept=False)  # intercept already added\n",
    "ridge.fit(X_tr_const, y_tr)\n",
    "\n",
    "y_pred_tr_ridge = ridge.predict(X_tr_const)\n",
    "y_pred_te_ridge = ridge.predict(X_test_const)\n",
    "\n",
    "r2_train = r2_score(y_tr, y_pred_tr_ridge)\n",
    "r2_test = r2_score(y_test, y_pred_te_ridge)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_te_ridge))\n",
    "\n",
    "print(f\"R² train: {r2_train:.4f}, R² test: {r2_test:.4f}, RMSE test: {rmse_test:.6f}\")\n",
    "\n",
    "# --- View coefficients (with names if available) ---\n",
    "coef_names = [\"const\"] + [f\"x{i}\" for i in range(X_tr.shape[1])]\n",
    "for name, coef in zip(coef_names, ridge.coef_):\n",
    "    print(f\"{name:<8} {coef: .6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68c86250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00994603,  0.02722205,  0.00691171, ...,  0.00945086,\n",
       "       -0.04514044, -0.05301743], shape=(104916,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_te_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5925ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² = -0.0073\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mR² = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m,\u001b[32m8\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43msns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscatterplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_pred_te_ridge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m plt.xlabel(\u001b[33m\"\u001b[39m\u001b[33mTrue\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m plt.ylabel(\u001b[33m\"\u001b[39m\u001b[33mPredicted\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/seaborn/relational.py:615\u001b[39m, in \u001b[36mscatterplot\u001b[39m\u001b[34m(data, x, y, hue, size, style, palette, hue_order, hue_norm, sizes, size_order, size_norm, markers, style_order, legend, ax, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscatterplot\u001b[39m(\n\u001b[32m    607\u001b[39m     data=\u001b[38;5;28;01mNone\u001b[39;00m, *,\n\u001b[32m    608\u001b[39m     x=\u001b[38;5;28;01mNone\u001b[39;00m, y=\u001b[38;5;28;01mNone\u001b[39;00m, hue=\u001b[38;5;28;01mNone\u001b[39;00m, size=\u001b[38;5;28;01mNone\u001b[39;00m, style=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    612\u001b[39m     **kwargs\n\u001b[32m    613\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     p = \u001b[43m_ScatterPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegend\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    621\u001b[39m     p.map_hue(palette=palette, order=hue_order, norm=hue_norm)\n\u001b[32m    622\u001b[39m     p.map_size(sizes=sizes, order=size_order, norm=size_norm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/seaborn/relational.py:396\u001b[39m, in \u001b[36m_ScatterPlotter.__init__\u001b[39m\u001b[34m(self, data, variables, legend)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *, data=\u001b[38;5;28;01mNone\u001b[39;00m, variables={}, legend=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    388\u001b[39m \n\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# TODO this is messy, we want the mapping to be agnostic about\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;66;03m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[32m    391\u001b[39m     \u001b[38;5;66;03m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28mself\u001b[39m._default_size_range = (\n\u001b[32m    393\u001b[39m         np.r_[\u001b[32m.5\u001b[39m, \u001b[32m2\u001b[39m] * np.square(mpl.rcParams[\u001b[33m\"\u001b[39m\u001b[33mlines.markersize\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    394\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    398\u001b[39m     \u001b[38;5;28mself\u001b[39m.legend = legend\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/seaborn/_base.py:634\u001b[39m, in \u001b[36mVectorPlotter.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28mself\u001b[39m._var_ordered = {\u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[32m    638\u001b[39m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mhue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msize\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/seaborn/_base.py:679\u001b[39m, in \u001b[36mVectorPlotter.assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    675\u001b[39m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[32m    676\u001b[39m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[32m    677\u001b[39m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[32m    678\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_format = \u001b[33m\"\u001b[39m\u001b[33mlong\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m     plot_data = \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m     frame = plot_data.frame\n\u001b[32m    681\u001b[39m     names = plot_data.names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/seaborn/_core/data.py:58\u001b[39m, in \u001b[36mPlotData.__init__\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     53\u001b[39m     data: DataSource,\n\u001b[32m     54\u001b[39m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[32m     55\u001b[39m ):\n\u001b[32m     57\u001b[39m     data = handle_data_source(data)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     frame, names, ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.frame = frame\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.names = names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/seaborn/_core/data.py:265\u001b[39m, in \u001b[36mPlotData._assign_variables\u001b[39m\u001b[34m(self, data, variables)\u001b[39m\n\u001b[32m    260\u001b[39m             ids[key] = \u001b[38;5;28mid\u001b[39m(val)\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# Construct a tidy plot DataFrame. This will convert a number of\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# types automatically, aligning on index in case of pandas objects\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# TODO Note: this fails when variable specs *only* have scalars!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m frame = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frame, names, ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/pandas/core/frame.py:782\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    776\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    777\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    778\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    781\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/pandas/core/internals/construction.py:664\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    662\u001b[39m         raw_lengths.append(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[32m    663\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m val.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m664\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[32m    667\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mIf using all scalar values, you must pass an index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Per-column arrays must each be 1-dimensional"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_te_ridge)\n",
    "print(f\"R² = {r2:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x=y_test, y=y_pred_te_ridge, s=25, alpha=0.6, edgecolor=None)\n",
    "plt.xlabel(\"True\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4c274",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
