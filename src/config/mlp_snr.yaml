model:
  name: mlp
  hparams:
    mlp_hidden_sizes:
      - 512
      - 256
      - 256
      - 128
    mlp_activation:
      - relu
      - relu
      - relu
      - relu
    dropout_rate: 0
    lstm_hidden_sizes:
      - 256
      - 256
    lstm_dropout: 0
    bidirectional: false
    readout: last
    use_ln: false

    conv_channels:
      - 64
      - 128
      - 256
    conv_activation:
      - relu
      - relu
      - relu
    kernel_size: 3
    padding: 1
    pool: adaptive_max
    pool_k: 4
    use_bn: false

    output_activation: linear
    n_layers: 2
data: 
  df_long: 'preds_v2.parquet' # if left out the pipeline takes it automatically
  df_master: # if left out the pipeline takes it automatically


trainer:
  hparams:
    epochs: 50
    batch_size: 512
    torch_patience: 10
    min_delta: 1e-10
    optuna_patience: 1000
    loss: mse
    metrics:
      - mae
      - mse
      - dir_acc
      - qlike
    val_every: 1
    optimizer_type: adam 
    weight_decay: 0.01
    lr: 0.00019243322503857425

walkforward:
  target_col: pred_mlp_100_adam
  lookback: 0
  ratio_train: 3
  ratio_val: 1
  ratio_test: 1
  step: 1197
  lags: 100
  max_folds: null
  min_folds: null
  scale: False
  annualize: true
  scale_type: 
  clip: 0
  noise: []

experiment:
  name: mlp_adam_snr
  hyperparams_search: False
  store_test_loss: True
  monitor: val_loss
  mode: min
  type: volatility
  random_state: 123
  store_test_loss: True
