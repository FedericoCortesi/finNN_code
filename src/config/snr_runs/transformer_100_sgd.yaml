model:
  name: transformer
  hparams:
    mlp_hidden_sizes:
    - 128
    - 64
    mlp_activation:
    - relu
    - relu
    dropout_rate: 0
    lstm_hidden_sizes:
    - 256
    - 256
    lstm_dropout: 0
    bidirectional: false
    use_ln: true
    conv_channels:
    - 64
    - 128
    - 256
    conv_activation:
    - relu
    - relu
    - relu
    kernel_size: 3
    padding: 1
    pool: adaptive_max
    pool_k: 4
    use_bn: false
    d_model: 128
    nhead: 8
    num_layers: 2
    dim_feedforward: 512
    transformer_dropout: 0
    pe_dropout: 0.05
    activation: gelu
    projection: linear
    readout: mean
    output_activation: linear
    n_layers: 2
  search: {}
trainer:
  hparams:
    epochs: 20
    batch_size: 512
    torch_patience: 10
    min_delta: 1e-10
    optuna_patience: 10
    loss: mse
    metrics:
    - mae
    - mse
    - dir_acc
    - qlike
    val_every: 1
    optimizer_type: sgd
    lr: 0.0028016351587162596
    weight_decay: 0.013949386065204183
    initialization: null
  search:
    lr:
      low: 1.0e-05
      high: 0.1
      log: true
      type: float
    weight_decay:
      low: 0
      high: 0.1
      log: false
      type: float
walkforward:
  target_col: pred_transformer_100_sgd
  lookback: 0
  ratio_train: 3
  ratio_val: 1
  ratio_test: 1
  step: 1197
  lags: 100
  max_folds: null
  min_folds: null
  scale: false
  annualize: true
  portfolios: 0
  noise:
  - 0.1
  - 0.5900000000000001
  - 1.08
  - 1.5700000000000003
  - 2.06
  - 2.5500000000000003
  - 3.0400000000000005
  - 3.5300000000000002
  - 4.0200000000000005
  - 4.51
  - 5.0
  scale_type: logstandard
  clip: 0.1
experiment:
  name: transformer_100_sgd_snr
  hyperparams_search: false
  monitor: val_loss
  mode: min
  type: volatility
  n_trials: 15
  random_state: 1234
  n_steps: null
  merge_train_val: false
  store_test_loss: true
data:
  df_path: null
  df_master: null
  df_long: preds_v2.parquet
