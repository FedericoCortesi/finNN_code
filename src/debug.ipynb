{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55393ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b1073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from config.config_types import AppConfig\n",
    "from utils.logging_utils import ExperimentLogger\n",
    "from training_routine.trainer import Trainer            \n",
    "from pipeline.walkforward import WFCVGenerator\n",
    "from pipeline.wf_config import WFConfig\n",
    "from hyperparams_search.search_utils import sample_hparams_into_cfg\n",
    "#from hyperparams_search.torch_estimator import TorchFoldEstimator\n",
    "#from hyperparams_search.randomsearch import RandomSearch\n",
    "\n",
    "from utils.gpu_test import gpu_test\n",
    "from utils.paths import CONFIG_DIR\n",
    "from utils.custom_formatter import setup_logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from utils.logging_utils import ExperimentLogger\n",
    "from training_routine.trainer import Trainer            \n",
    "from pipeline.walkforward import WFCVGenerator\n",
    "from pipeline.wf_config import WFConfig\n",
    "from utils.gpu_test import gpu_test\n",
    "from utils.paths import CONFIG_DIR\n",
    "from utils.custom_formatter import setup_logger\n",
    "\n",
    "from models import create_model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f8fb88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m12:02:27 - Experiment - INFO - GPU check complete. (1149415777.py:6)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppConfig(model=ModelConfig(name='mlp', hparams={'output_activation': 'linear'}, search={'dropout_rate': FloatSpec(low=0.0, high=0.5, log=False, type='float'), 'activation': CatSpec(choices=['relu', 'gelu', 'tanh'], type='cat'), 'n_layers': IntSpec(low=1, high=10, type='int'), 'n_hidden': IntSpec(low=64, high=1024, type='int')}), trainer=TrainerConfig(hparams={'epochs': 50, 'batch_size': 512, 'metrics': ['mae', 'mse', 'dir_acc'], 'loss': 'mse', 'val_every': 1}, search={'lr': FloatSpec(low=1e-05, high=0.01, log=True, type='float'), 'weight_decay': FloatSpec(low=0, high=0.01, log=False, type='float'), 'batch_size': IntSpec(low=32, high=256, type='int')}), walkforward=WFConfig(ratio_train=3, ratio_val=1, ratio_test=1, step=251, lags=20, max_folds=None), experiment=ExperimentConfig(name='mlp_random_search', hyperparams_search=True, monitor='val_loss', mode='min', type='price_prediction', n_trials=25, random_state=42), data={'target_col': 'y', 'feature_cols': ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19'], 'standardize': True})\n",
      "ModelConfig(name='mlp', hparams={'output_activation': 'linear'}, search={'dropout_rate': FloatSpec(low=0.0, high=0.5, log=False, type='float'), 'activation': CatSpec(choices=['relu', 'gelu', 'tanh'], type='cat'), 'n_layers': IntSpec(low=1, high=10, type='int'), 'n_hidden': IntSpec(low=64, high=1024, type='int')})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup logger\n",
    "console_logger = setup_logger(\"Experiment\", level=\"INFO\")\n",
    "\n",
    "# --- GPU check (PyTorch) ---\n",
    "gpu_test()\n",
    "console_logger.info(\"GPU check complete.\")\n",
    "\n",
    "# -------- load config --------\n",
    "cfg = AppConfig.from_dict(f\"{CONFIG_DIR}/random_debug.yaml\")\n",
    "print(cfg)\n",
    "\n",
    "print(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac288db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-10-18 12:05:12,938] A new study created in memory with name: no-name-9aee4c37-cc5c-40ca-948e-3e60bba53900\n",
      "\u001b[34;20m12:05:12 - Search_utils - DEBUG - model_keys: ['dropout_rate', 'activation', 'n_layers', 'n_hidden', 'output_activation'] (search_utils.py:66)\u001b[0m\n",
      "\u001b[34;20m12:05:12 - Search_utils - DEBUG - cfg[\"model\"]: {'name': 'mlp', 'hparams': {'output_activation': 'linear'}, 'search': {'dropout_rate': {'low': 0.0, 'high': 0.5, 'log': False, 'type': 'float'}, 'activation': {'choices': ['relu', 'gelu', 'tanh'], 'type': 'cat'}, 'n_layers': {'low': 1, 'high': 10, 'type': 'int'}, 'n_hidden': {'low': 64, 'high': 1024, 'type': 'int'}}} (search_utils.py:67)\u001b[0m\n",
      "\u001b[34;20m12:05:12 - Search_utils - DEBUG - cfg[\"model\"] after the cycle: {'name': 'mlp', 'hparams': {'output_activation': 'linear'}, 'search': {'dropout_rate': {'low': 0.0, 'high': 0.5, 'log': False, 'type': 'float'}, 'activation': {'choices': ['relu', 'gelu', 'tanh'], 'type': 'cat'}, 'n_layers': {'low': 1, 'high': 10, 'type': 'int'}, 'n_hidden': {'low': 64, 'high': 1024, 'type': 'int'}}} (search_utils.py:71)\u001b[0m\n",
      "\u001b[34;20m12:05:12 - Search_utils - DEBUG - parsed_config[\"model\"]: {'name': 'mlp', 'hparams': {'output_activation': None, 'dropout_rate': None, 'activation': None, 'n_layers': None, 'n_hidden': None}, 'search': {'dropout_rate': {'low': 0.0, 'high': 0.5, 'log': False, 'type': 'float'}, 'activation': {'choices': ['relu', 'gelu', 'tanh'], 'type': 'cat'}, 'n_layers': {'low': 1, 'high': 10, 'type': 'int'}, 'n_hidden': {'low': 64, 'high': 1024, 'type': 'int'}}} (search_utils.py:72)\u001b[0m\n",
      "\u001b[34;20m12:05:12 - Search_utils - DEBUG - mdl_search: {'dropout_rate': {'low': 0.0, 'high': 0.5, 'log': False, 'type': 'float'}, 'activation': {'choices': ['relu', 'gelu', 'tanh'], 'type': 'cat'}, 'n_layers': {'low': 1, 'high': 10, 'type': 'int'}, 'n_hidden': {'low': 64, 'high': 1024, 'type': 'int'}} (search_utils.py:87)\u001b[0m\n",
      "\u001b[34;20m12:05:12 - Search_utils - DEBUG - k,v: ('output_activation', None) (search_utils.py:135)\u001b[0m\n",
      "\u001b[34;20m12:05:12 - Search_utils - DEBUG - cfg[\"model\"][\"hparams\"][k]: linear (search_utils.py:136)\u001b[0m\n",
      "\u001b[31;1m12:05:12 - Search_utils - CRITICAL - {'data': {'target_col': 'y', 'feature_cols': ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19'], 'standardize': True}, 'trainer': {'hparams': {'epochs': 50, 'batch_size': 512, 'metrics': ['mae', 'mse', 'dir_acc'], 'loss': 'mse', 'val_every': 1}, 'search': {'lr': {'low': 1e-05, 'high': 0.01, 'log': True, 'type': 'float'}, 'weight_decay': {'low': 0, 'high': 0.01, 'log': False, 'type': 'float'}, 'batch_size': {'low': 32, 'high': 256, 'type': 'int'}}, 'lr': 0.0001329291894316216, 'weight_decay': 0.009507143064099163, 'batch_size': 196}, 'experiment': {'name': 'mlp_random_search', 'hyperparams_search': True, 'monitor': 'val_loss', 'mode': 'min', 'type': 'price_prediction', 'n_trials': 25, 'random_state': 42}, 'walkforward': {'ratio_train': 3, 'ratio_val': 1, 'ratio_test': 1, 'step': 251, 'lags': 20, 'max_folds': None}, 'model': {'name': 'mlp', 'hparams': {'output_activation': 'linear', 'dropout_rate': 0.02904180608409973, 'activation': 'relu', 'n_layers': 9, 'n_hidden': [641, 744, 83, 996, 863, 268, 238, 240, 356], 'hidden_sizes': [641, 744, 83, 996, 863, 268, 238, 240, 356]}, 'search': {'dropout_rate': {'low': 0.0, 'high': 0.5, 'log': False, 'type': 'float'}, 'activation': {'choices': ['relu', 'gelu', 'tanh'], 'type': 'cat'}, 'n_layers': {'low': 1, 'high': 10, 'type': 'int'}, 'n_hidden': {'low': 64, 'high': 1024, 'type': 'int'}}}} (search_utils.py:138)\u001b[0m\n",
      "\u001b[31;1m12:05:12 - Experiment - CRITICAL - ModelConfig(name='mlp', hparams={'output_activation': 'linear', 'dropout_rate': 0.02904180608409973, 'activation': 'relu', 'n_layers': 9, 'n_hidden': [641, 744, 83, 996, 863, 268, 238, 240, 356], 'hidden_sizes': [641, 744, 83, 996, 863, 268, 238, 240, 356]}, search={'dropout_rate': FloatSpec(low=0.0, high=0.5, log=False, type='float'), 'activation': CatSpec(choices=['relu', 'gelu', 'tanh'], type='cat'), 'n_layers': IntSpec(low=1, high=10, type='int'), 'n_hidden': IntSpec(low=64, high=1024, type='int')}) (4283666936.py:50)\u001b[0m\n",
      "\u001b[33;20m12:05:12 - ExperimentLogger - WARNING - Experiment with name 'mlp_random_search' already exists: /orcd/home/002/corte911/code/finNN_code/src/price_prediction/experiments/exp_007_mlp_random_search. Creating a new trial under this experiment. (logging_utils.py:64)\u001b[0m\n",
      "\u001b[38;20m12:05:12 - ExperimentLogger - INFO - Experiment directory: /orcd/home/002/corte911/code/finNN_code/src/price_prediction/experiments/exp_007_mlp_random_search (logging_utils.py:91)\u001b[0m\n",
      "\u001b[38;20m12:05:12 - ExperimentLogger - INFO - Trial directory: /orcd/home/002/corte911/code/finNN_code/src/price_prediction/experiments/exp_007_mlp_random_search/trial_000 (logging_utils.py:136)\u001b[0m\n",
      "\u001b[33;20m12:05:12 - MLP - WARNING - Passed string relu for activations, using ['relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu'] instead (mlp.py:26)\u001b[0m\n",
      "[W 2025-10-18 12:05:12,984] Trial 0 failed with parameters: {'trainer.lr': 0.0001329291894316216, 'trainer.weight_decay': 0.009507143064099163, 'trainer.batch_size': 196, 'model.activation': 'relu', 'model.dropout_rate': 0.02904180608409973, 'model.n_layers': 9, 'model.width_0': 641, 'model.width_1': 744, 'model.width_2': 83, 'model.width_3': 996, 'model.width_4': 863, 'model.width_5': 268, 'model.width_6': 238, 'model.width_7': 240, 'model.width_8': 356} because of the following error: TypeError(\"'TrainerConfig' object is not subscriptable\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_3356119/4283666936.py\", line 72, in objective\n",
      "    val_metric = trial_trainer.fit_eval_fold(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/orcd/home/002/corte911/code/finNN_code/src/training_routine/trainer.py\", line 13, in fit_eval_fold\n",
      "    from utils.logging_utils import ExperimentLogger\n",
      "            ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/orcd/home/002/corte911/code/finNN_code/src/training_routine/trainer.py\", line 4, in compile\n",
      "TypeError: 'TrainerConfig' object is not subscriptable\n",
      "[W 2025-10-18 12:05:12,986] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'TrainerConfig' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# ---- build study (TPE + ASHA) and run for this fold ----\u001b[39;00m\n\u001b[32m     81\u001b[39m study = optuna.create_study(\n\u001b[32m     82\u001b[39m     direction=direction,\n\u001b[32m     83\u001b[39m     sampler=TPESampler(seed=cfg.experiment.random_state, multivariate=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     84\u001b[39m     pruner=SuccessiveHalvingPruner(min_resource=\u001b[32m3\u001b[39m, reduction_factor=\u001b[32m3\u001b[39m),  \u001b[38;5;66;03m# ASHA-like pruning\u001b[39;00m\n\u001b[32m     85\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# ---- log & (optionally) retrain best-once for the fold ----\u001b[39;00m\n\u001b[32m     89\u001b[39m console_logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Best value:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/optuna/study/_optimize.py:258\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    254\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    255\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    257\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 72\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m trial.should_prune()\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# 6) fit/eval only on THIS fold’s (train,val). Your `data` tuple already contains them.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m val_metric = \u001b[43mtrial_trainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_eval_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;66;43;03m#    model, data, trial=trial.number, fold=fold, report_cb=report_cb\u001b[39;49;00m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# 7) return the scalar according to direction\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m val_metric\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/corte911/code/finNN_code/src/training_routine/trainer.py:13\u001b[39m, in \u001b[36mfit_eval_fold\u001b[39m\u001b[34m(self, model, data, fold, trial, merge_train_val)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#import warnings\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#warnings.simplefilter(action=\"ignore\", module=torch)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogging_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExperimentLogger\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcustom_formatter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconfig\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AppConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/corte911/code/finNN_code/src/training_routine/trainer.py:4\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mTypeError\u001b[39m: 'TrainerConfig' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------- data + components --------\n",
    "#logger = ExperimentLogger(cfg)\n",
    "\n",
    "\n",
    "wf = WFCVGenerator(config=cfg.walkforward)\n",
    "\n",
    "# instantiate trainer (PyTorch)\n",
    "#trainer = Trainer(cfg, logger)\n",
    "\n",
    "# model input size: number of lags (columns are constant across folds)\n",
    "input_shape = cfg.walkforward.lags            # int is fine; build_model handles it\n",
    "max_folds = cfg.walkforward.max_folds\n",
    "\n",
    "if cfg.model.name.lower() == \"cnn1d\":\n",
    "    input_shape = (1, cfg.walkforward.lags)  # (C, L)\n",
    "elif cfg.model.name.lower() == \"mlp\":\n",
    "    input_shape = (cfg.walkforward.lags,)\n",
    "else:\n",
    "    console_logger.warning(f\"Model: {cfg.model.name} not recognized!\")\n",
    "\n",
    "# Get bool for search\n",
    "hyperparams_search = cfg.experiment.hyperparams_search\n",
    "\n",
    "\n",
    "# -------- train per fold --------\n",
    "for fold, data in enumerate(wf.folds()):\n",
    "    if max_folds is not None and fold >= max_folds:\n",
    "        break  # allow running subset of folds\n",
    "\n",
    "    if hyperparams_search:\n",
    "        # ---- pick a single fold 'data' and run Optuna on it ----\n",
    "        direction = \"minimize\" if cfg.experiment.mode.lower() == \"min\" else \"maximize\"\n",
    "        n_trials  = getattr(cfg.experiment, \"n_trials\", 50)\n",
    "        n_jobs    = 1  # for a single fold on one machine; raise if you parallelize\n",
    "\n",
    "        # Compute (fixed) input shape for this base cfg; it won't change with hparams\n",
    "        def make_input_shape(c):\n",
    "            return (c.walkforward.lags, )\n",
    "\n",
    "        input_shape = make_input_shape(cfg)\n",
    "\n",
    "        # ---- define Optuna objective for this *one fold* ----\n",
    "        def objective(trial: optuna.trial.Trial) -> float:\n",
    "            # 1) sample hparams → a NEW cfg (dict or dataclass, depending on your function)\n",
    "\n",
    "            trial_cfg = sample_hparams_into_cfg(cfg, trial)  # returns same \"type\" you pass in\n",
    "\n",
    "            trial_cfg = AppConfig.from_dict(trial_cfg)\n",
    "\n",
    "            console_logger.critical(trial_cfg.model)\n",
    "            #console_logger.critical(trial_cfg.trainer)\n",
    "\n",
    "\n",
    "            # 2) fresh trainer per trial (avoid any state carry-over)\n",
    "            trial_logger = ExperimentLogger(trial_cfg)\n",
    "            trial_logger.begin_trial(trial.number)\n",
    "\n",
    "            trial_trainer = Trainer(trial_cfg, trial_logger)\n",
    "\n",
    "            # 3) (re)compute input shape from the *trial* cfg if model family could change\n",
    "            shp = make_input_shape(trial_cfg)\n",
    "\n",
    "            # 4) build a fresh model for this trial\n",
    "            model = create_model(trial_cfg.model, shp)\n",
    "\n",
    "            # 5) epoch-wise reporting so ASHA can prune early\n",
    "            def report_cb(epoch: int, val_metric: float):\n",
    "                trial.report(val_metric, step=epoch)   # strictly increasing step\n",
    "                return trial.should_prune()\n",
    "\n",
    "            # 6) fit/eval only on THIS fold’s (train,val). Your `data` tuple already contains them.\n",
    "            val_metric = trial_trainer.fit_eval_fold(\n",
    "            #    model, data, trial=trial.number, fold=fold, report_cb=report_cb\n",
    "                model, data, trial=trial.number, fold=fold\n",
    "            )\n",
    "\n",
    "            # 7) return the scalar according to direction\n",
    "            return val_metric  # study direction handles min/max\n",
    "\n",
    "        # ---- build study (TPE + ASHA) and run for this fold ----\n",
    "        study = optuna.create_study(\n",
    "            direction=direction,\n",
    "            sampler=TPESampler(seed=cfg.experiment.random_state, multivariate=True),\n",
    "            pruner=SuccessiveHalvingPruner(min_resource=3, reduction_factor=3),  # ASHA-like pruning\n",
    "        )\n",
    "        study.optimize(objective, n_trials=n_trials, n_jobs=n_jobs)\n",
    "\n",
    "        # ---- log & (optionally) retrain best-once for the fold ----\n",
    "        console_logger.info(f\"[Fold {fold}] Best value:  {study.best_value:.6f}\")\n",
    "        console_logger.info(f\"[Fold {fold}] Best params: {study.best_params}\")\n",
    "\n",
    "        # Optional: rebuild a cfg from best params and do a final “full” run (e.g., full epochs)\n",
    "        best_cfg = sample_hparams_into_cfg(cfg, optuna.trial.FixedTrial(study.best_params))\n",
    "        best_logger  = ExperimentLogger(best_cfg)\n",
    "        best_trainer = Trainer(best_cfg, best_logger)\n",
    "        best_model   = create_model(best_cfg.model, input_shape)\n",
    "\n",
    "        # If you keep shorter epochs during search, you can override here:\n",
    "        # best_cfg.trainer.params[\"epochs\"] = cfg.trainer.params[\"epochs\"]  # full epochs\n",
    "\n",
    "        _ = best_trainer.fit_eval_fold(best_model, data, trial=-1, fold=fold, report_cb=None)\n",
    "\n",
    "        # --- log best results ---\n",
    "        #console_logger.info(f\"[Fold {fold}] Best params: {result['best_params']}\")\n",
    "        #console_logger.info(f\"[Fold {fold}] Best {cfg.experiment.monitor}: {result['best_selection_score']:.6f}\")\n",
    "        \n",
    "\n",
    "\n",
    "    else:\n",
    "        # Keep model creation inside the loop to avoid weight leakage across folds\n",
    "        model = create_model(cfg.model, input_shape)       \n",
    "\n",
    "        if fold == 0:\n",
    "            console_logger.critical(f\"model: {model}\")\n",
    "\n",
    "        trainer.fit_eval_fold(model, data, trial=0, fold=fold)\n",
    "\n",
    "console_logger.warning(\"Training completed!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
