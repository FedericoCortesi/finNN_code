{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55393ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b1073b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from config.config_types import AppConfig\n",
    "from utils.logging_utils import ExperimentLogger\n",
    "from training_routine.trainer import Trainer            \n",
    "from pipeline.walkforward import WFCVGenerator\n",
    "from pipeline.preprocessing import preprocess\n",
    "from hyperparams_search.search_utils import sample_hparams_into_cfg\n",
    "#from hyperparams_search.torch_estimator import TorchFoldEstimator\n",
    "#from hyperparams_search.randomsearch import RandomSearch\n",
    "\n",
    "from utils.gpu_test import gpu_test\n",
    "from utils.paths import CONFIG_DIR\n",
    "from utils.custom_formatter import setup_logger\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from utils.logging_utils import ExperimentLogger\n",
    "from training_routine.trainer import Trainer            \n",
    "from pipeline.walkforward import WFCVGenerator\n",
    "from utils.gpu_test import gpu_test\n",
    "from utils.paths import CONFIG_DIR, SP500COPY_PATH, SP500_PATH\n",
    "from utils.custom_formatter import setup_logger\n",
    "\n",
    "from models import create_model \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b6354",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d9ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34;20m17:32:25 - Preprocessing - DEBUG - percentage of nan returns 0.0034% (preprocessing.py:93)\u001b[0m\n",
      "\u001b[34;20m17:32:25 - WFCVGenerator - DEBUG - WFConfig(train=753d, val=251d, test=251d, lags=20, step=251, max_folds=None) (walkforward.py:29)\u001b[0m\n",
      "\u001b[34;20m17:32:25 - WFCVGenerator - DEBUG - Loading data via preprocess() (walkforward.py:44)\u001b[0m\n",
      "\u001b[34;20m17:32:26 - Preprocessing - DEBUG - percentage of nan returns 0.0034% (preprocessing.py:93)\u001b[0m\n",
      "\u001b[34;20m17:32:26 - WFCVGenerator - DEBUG - Loaded df: shape=(3155303, 3) dtypes={'t': dtype('int16'), 'ret': Float64Dtype(), 'permno': Int64Dtype()} head=\n",
      " t       ret  permno\n",
      " 0 -0.012107   10078\n",
      " 1 -0.062092   10078\n",
      " 2  0.001742   10078 (walkforward.py:66)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cfg = AppConfig.from_dict(f\"{CONFIG_DIR}/debug.yaml\")\n",
    "\n",
    "preprocess(path=SP500_PATH)\n",
    "\n",
    "\n",
    "wf = WFCVGenerator(config=cfg.walkforward)\n",
    "\n",
    "df = wf.df_master\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f027f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8fb88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m17:32:40 - Experiment - INFO - GPU check complete. (3647976701.py:6)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppConfig(model=ModelConfig(name='mlp', hparams={'hidden_sizes': [1024, 1024, 1024, 1024, 1024, 1024], 'dropout_rate': 0, 'activation': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu'], 'output_activation': 'linear', 'learning_rate': 0.001}, search={}), trainer=TrainerConfig(hparams={'epochs': 50, 'batch_size': 512, 'lr': 0.001, 'loss': 'mse', 'metrics': ['mae', 'mse', 'dir_acc'], 'weight_decay': 0, 'val_every': 1, 'search': False}, search={}), walkforward=WFConfig(ratio_train=3, ratio_val=1, ratio_test=1, step=251, lags=20, max_folds=None), experiment=ExperimentConfig(name='MLP_linreg', hyperparams_search=False, monitor='val_loss', mode='min', type='price_prediction', n_trials=20, random_state=1234), data={'target_col': 'y'})\n",
      "WFConfig(ratio_train=3, ratio_val=1, ratio_test=1, step=251, lags=20, max_folds=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setup logger\n",
    "console_logger = setup_logger(\"Experiment\", level=\"INFO\")\n",
    "\n",
    "# --- GPU check (PyTorch) ---\n",
    "gpu_test()\n",
    "console_logger.info(\"GPU check complete.\")\n",
    "\n",
    "# -------- load config --------\n",
    "cfg = AppConfig.from_dict(f\"{CONFIG_DIR}/debug.yaml\")\n",
    "print(cfg)\n",
    "\n",
    "print(cfg.walkforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac288db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34;20m17:32:41 - WFCVGenerator - DEBUG - WFConfig(train=753d, val=251d, test=251d, lags=20, step=251, max_folds=None) (walkforward.py:29)\u001b[0m\n",
      "\u001b[34;20m17:32:41 - WFCVGenerator - DEBUG - Loading data via preprocess() (walkforward.py:44)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34;20m17:32:42 - Preprocessing - DEBUG - percentage of nan returns 0.0034% (preprocessing.py:93)\u001b[0m\n",
      "\u001b[34;20m17:32:43 - WFCVGenerator - DEBUG - Loaded df: shape=(3155303, 3) dtypes={'t': dtype('int16'), 'ret': Float64Dtype(), 'permno': Int64Dtype()} head=\n",
      " t       ret  permno\n",
      " 0 -0.012107   10078\n",
      " 1 -0.062092   10078\n",
      " 2  0.001742   10078 (walkforward.py:66)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# -------- data + components --------\n",
    "#logger = ExperimentLogger(cfg)\n",
    "\n",
    "\n",
    "wf = WFCVGenerator(config=cfg.walkforward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d77516b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m17:32:52 - Experiment - WARNING - No hyperparams search for this experiment (3305620216.py:30)\u001b[0m\n",
      "\u001b[33;20m17:32:52 - ExperimentLogger - WARNING - Experiment with name 'MLP_linreg' already exists: /orcd/home/002/corte911/code/finNN_code/src/price_prediction/experiments/exp_008_MLP_linreg. If the experiment is of type `search`, 'trial_serch_best' will be overwritten!Creating a new trial under this experiment. (logging_utils.py:64)\u001b[0m\n",
      "\u001b[38;20m17:32:52 - ExperimentLogger - INFO - Experiment directory: /orcd/home/002/corte911/code/finNN_code/src/price_prediction/experiments/exp_008_MLP_linreg (logging_utils.py:92)\u001b[0m\n",
      "\u001b[38;20m17:32:52 - ExperimentLogger - INFO - Trial directory: /orcd/home/002/corte911/code/finNN_code/src/price_prediction/experiments/exp_008_MLP_linreg/trial_20251019_173252 (logging_utils.py:135)\u001b[0m\n",
      "\u001b[38;20m17:32:55 - Trainer - INFO - Fitting fold 00 (trial 00) on torch.Size([364349, 21]) samples, val torch.Size([115317, 21]), test torch.Size([115175, 21]) (trainer.py:180)\u001b[0m\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0] failed while attempting to run meta for aten.mm.default\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0] Traceback (most recent call last):\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2013, in _dispatch_impl\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     r = func(*args, **kwargs)\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_ops.py\", line 716, in __call__\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     return self._op(*args, **kwargs)\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_prims_common/wrappers.py\", line 273, in _fn\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     result = fn(*args, **kwargs)\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]              ^^^^^^^^^^^^^^^^^^^\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_meta_registrations.py\", line 2100, in meta_mm\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     torch._check(\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/__init__.py\", line 1564, in _check\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     _check_with(RuntimeError, cond, message)\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]   File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/__init__.py\", line 1546, in _check_with\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0]     raise error_type(message_evaluated)\n",
      "E1019 17:32:56.087000 3657465 /orcd/home/002/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2017] [0/0] RuntimeError: a and b must have same reduction dim, but got [512, 21] X [20, 1024].\n"
     ]
    },
    {
     "ename": "TorchRuntimeError",
     "evalue": "Failed running call_function <built-in function linear>(*(FakeTensor(..., device='cuda:0', size=(512, 21)), Parameter(FakeTensor(..., device='cuda:0', size=(1024, 20), requires_grad=True)), Parameter(FakeTensor(..., device='cuda:0', size=(1024,), requires_grad=True))), **{}):\na and b must have same reduction dim, but got [512, 21] X [20, 1024].\n\nfrom user code:\n   File \"/orcd/home/002/corte911/code/finNN_code/src/models/mlp.py\", line 82, in forward\n    return self.net(x)\n  File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 250, in forward\n    input = module(input)\n  File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTorchRuntimeError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fold == \u001b[32m0\u001b[39m:\n\u001b[32m     45\u001b[39m             console_logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m         \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_eval_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m console_logger.warning(\u001b[33m\"\u001b[39m\u001b[33mTraining completed!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/corte911/code/finNN_code/src/training_routine/trainer.py:195\u001b[39m, in \u001b[36mTrainer.fit_eval_fold\u001b[39m\u001b[34m(self, model, data, fold, trial, merge_train_val, report_cb)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m amp_ctx:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m.squeeze(-\u001b[32m1\u001b[39m)\n\u001b[32m    196\u001b[39m     loss = \u001b[38;5;28mself\u001b[39m.loss_fn(pred, yb)\n\u001b[32m    197\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:465\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    460\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    461\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    462\u001b[39m )\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    468\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    469\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    470\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1269\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1263\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1264\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1265\u001b[39m             )\n\u001b[32m   1267\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1269\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1271\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1064\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1062\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1066\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1067\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:526\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    510\u001b[39m compile_id = CompileId(frame_id, frame_compile_id)\n\u001b[32m    512\u001b[39m signpost_event(\n\u001b[32m    513\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    514\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m_convert_frame_assert._compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m     },\n\u001b[32m    524\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:924\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    922\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    923\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m guarded_code\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:666\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33m_compile.compile_inner\u001b[39m\u001b[33m\"\u001b[39m, phase_name=\u001b[33m\"\u001b[39m\u001b[33mentire_frame_compile\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    665\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m CompileTimeInstructionCounter.record():\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_utils_internal.py:87\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     90\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     91\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:699\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    697\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1322\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1319\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1320\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:219\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m exit_stack.enter_context(\n\u001b[32m    216\u001b[39m     torch.fx._symbolic_trace._maybe_revert_all_patches()\n\u001b[32m    217\u001b[39m )\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    221\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:634\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    633\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    636\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2796\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2795\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2796\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    982\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    984\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:582\u001b[39m, in \u001b[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation.reason)\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generic_context_manager_depth > \u001b[32m0\u001b[39m:\n\u001b[32m    585\u001b[39m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[32m    586\u001b[39m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001b[39m, in \u001b[36mInstructionTranslatorBase.CALL\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2277\u001b[39m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push=\u001b[32m1\u001b[39m)\n\u001b[32m   2278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m2279\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001b[39m, in \u001b[36mInstructionTranslatorBase._call\u001b[39m\u001b[34m(self, inst, call_kw)\u001b[39m\n\u001b[32m   2268\u001b[39m     kwargs = {}\n\u001b[32m   2270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2271\u001b[39m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[32m   2272\u001b[39m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2273\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2274\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2275\u001b[39m     \u001b[38;5;28mself\u001b[39m.kw_names = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:830\u001b[39m, in \u001b[36mInstructionTranslatorBase.call_function\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/lazy.py:156\u001b[39m, in \u001b[36m_create_realize_and_forward.<locals>.realize_and_forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(\u001b[38;5;28mgetattr\u001b[39m(VariableTracker, name))\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrealize_and_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:899\u001b[39m, in \u001b[36mUnspecializedNNModuleVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    891\u001b[39m ctx = (\n\u001b[32m    892\u001b[39m     record_nn_module_stack(\n\u001b[32m    893\u001b[39m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(mod)), \u001b[38;5;28mself\u001b[39m.get_nn_module_stack_source(), tx, mod\n\u001b[32m   (...)\u001b[39m\u001b[32m    896\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[32m    897\u001b[39m )\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvariables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUserFunctionVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:324\u001b[39m, in \u001b[36mUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_constant:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invoke_and_store_as_constant(\n\u001b[32m    321\u001b[39m         tx, \u001b[38;5;28mself\u001b[39m.fn, \u001b[38;5;28mself\u001b[39m.get_name(), args, kwargs\n\u001b[32m    322\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:111\u001b[39m, in \u001b[36mBaseUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_function\u001b[39m(\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    107\u001b[39m     tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    108\u001b[39m     args: \u001b[33m\"\u001b[39m\u001b[33mList[VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    109\u001b[39m     kwargs: \u001b[33m\"\u001b[39m\u001b[33mDict[str, VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    110\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mVariableTracker\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_user_function_return\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:836\u001b[39m, in \u001b[36mInstructionTranslatorBase.inline_user_function_return\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minline_user_function_return\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[32m    833\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    834\u001b[39m \u001b[33;03m    A call to some user defined function by inlining it.\u001b[39;00m\n\u001b[32m    835\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInliningInstructionTranslator\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3011\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call\u001b[39m\u001b[34m(cls, parent, func, args, kwargs)\u001b[39m\n\u001b[32m   3008\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   3009\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minline_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m, parent, func, args, kwargs):\n\u001b[32m   3010\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m patch.dict(counters, {\u001b[33m\"\u001b[39m\u001b[33munimplemented\u001b[39m\u001b[33m\"\u001b[39m: counters[\u001b[33m\"\u001b[39m\u001b[33minline_call\u001b[39m\u001b[33m\"\u001b[39m]}):\n\u001b[32m-> \u001b[39m\u001b[32m3011\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minline_call_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3139\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call_\u001b[39m\u001b[34m(parent, func, args, kwargs)\u001b[39m\n\u001b[32m   3137\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3138\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m strict_ctx:\n\u001b[32m-> \u001b[39m\u001b[32m3139\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3140\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3141\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObserved exception DURING INLING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    982\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    984\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:582\u001b[39m, in \u001b[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation.reason)\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generic_context_manager_depth > \u001b[32m0\u001b[39m:\n\u001b[32m    585\u001b[39m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[32m    586\u001b[39m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001b[39m, in \u001b[36mInstructionTranslatorBase.CALL\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2277\u001b[39m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push=\u001b[32m1\u001b[39m)\n\u001b[32m   2278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m2279\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001b[39m, in \u001b[36mInstructionTranslatorBase._call\u001b[39m\u001b[34m(self, inst, call_kw)\u001b[39m\n\u001b[32m   2268\u001b[39m     kwargs = {}\n\u001b[32m   2270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2271\u001b[39m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[32m   2272\u001b[39m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2273\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2274\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2275\u001b[39m     \u001b[38;5;28mself\u001b[39m.kw_names = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:830\u001b[39m, in \u001b[36mInstructionTranslatorBase.call_function\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:899\u001b[39m, in \u001b[36mUnspecializedNNModuleVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    891\u001b[39m ctx = (\n\u001b[32m    892\u001b[39m     record_nn_module_stack(\n\u001b[32m    893\u001b[39m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(mod)), \u001b[38;5;28mself\u001b[39m.get_nn_module_stack_source(), tx, mod\n\u001b[32m   (...)\u001b[39m\u001b[32m    896\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[32m    897\u001b[39m )\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvariables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUserFunctionVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:324\u001b[39m, in \u001b[36mUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_constant:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m invoke_and_store_as_constant(\n\u001b[32m    321\u001b[39m         tx, \u001b[38;5;28mself\u001b[39m.fn, \u001b[38;5;28mself\u001b[39m.get_name(), args, kwargs\n\u001b[32m    322\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:111\u001b[39m, in \u001b[36mBaseUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_function\u001b[39m(\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    107\u001b[39m     tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    108\u001b[39m     args: \u001b[33m\"\u001b[39m\u001b[33mList[VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    109\u001b[39m     kwargs: \u001b[33m\"\u001b[39m\u001b[33mDict[str, VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    110\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mVariableTracker\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_user_function_return\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:836\u001b[39m, in \u001b[36mInstructionTranslatorBase.inline_user_function_return\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minline_user_function_return\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, args, kwargs):\n\u001b[32m    833\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    834\u001b[39m \u001b[33;03m    A call to some user defined function by inlining it.\u001b[39;00m\n\u001b[32m    835\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInliningInstructionTranslator\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3011\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call\u001b[39m\u001b[34m(cls, parent, func, args, kwargs)\u001b[39m\n\u001b[32m   3008\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   3009\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minline_call\u001b[39m(\u001b[38;5;28mcls\u001b[39m, parent, func, args, kwargs):\n\u001b[32m   3010\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m patch.dict(counters, {\u001b[33m\"\u001b[39m\u001b[33munimplemented\u001b[39m\u001b[33m\"\u001b[39m: counters[\u001b[33m\"\u001b[39m\u001b[33minline_call\u001b[39m\u001b[33m\"\u001b[39m]}):\n\u001b[32m-> \u001b[39m\u001b[32m3011\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minline_call_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3139\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call_\u001b[39m\u001b[34m(parent, func, args, kwargs)\u001b[39m\n\u001b[32m   3137\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3138\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m strict_ctx:\n\u001b[32m-> \u001b[39m\u001b[32m3139\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3140\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3141\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObserved exception DURING INLING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:983\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    982\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    984\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:895\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:582\u001b[39m, in \u001b[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    580\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation.reason)\n\u001b[32m    581\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m582\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generic_context_manager_depth > \u001b[32m0\u001b[39m:\n\u001b[32m    585\u001b[39m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[32m    586\u001b[39m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2279\u001b[39m, in \u001b[36mInstructionTranslatorBase.CALL\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   2277\u001b[39m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push=\u001b[32m1\u001b[39m)\n\u001b[32m   2278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m2279\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:2273\u001b[39m, in \u001b[36mInstructionTranslatorBase._call\u001b[39m\u001b[34m(self, inst, call_kw)\u001b[39m\n\u001b[32m   2268\u001b[39m     kwargs = {}\n\u001b[32m   2270\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2271\u001b[39m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[32m   2272\u001b[39m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2273\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2274\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   2275\u001b[39m     \u001b[38;5;28mself\u001b[39m.kw_names = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:830\u001b[39m, in \u001b[36mInstructionTranslatorBase.call_function\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/torch.py:897\u001b[39m, in \u001b[36mTorchInGraphFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    888\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs[\u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m], variables.TensorVariable):\n\u001b[32m    889\u001b[39m                 \u001b[38;5;66;03m# Calling fake tensor propagation can mutate the out= tensor in\u001b[39;00m\n\u001b[32m    890\u001b[39m                 \u001b[38;5;66;03m# tx.output.tracked_fakes. tracked_fakes are used to apply\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    893\u001b[39m                 \u001b[38;5;66;03m# guards. So save the shape now, and check later if it has\u001b[39;00m\n\u001b[32m    894\u001b[39m                 \u001b[38;5;66;03m# changed. If it has, graph break.\u001b[39;00m\n\u001b[32m    895\u001b[39m                 fake_out_shape = kwargs[\u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m].proxy.node.meta[\u001b[33m\"\u001b[39m\u001b[33mexample_value\u001b[39m\u001b[33m\"\u001b[39m].shape\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m             tensor_variable = \u001b[43mwrap_fx_proxy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m                \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_proxy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcall_function\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfn_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m*\u001b[49m\u001b[43mproxy_args_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    906\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    907\u001b[39m                 \u001b[38;5;28misinstance\u001b[39m(tensor_variable, TensorVariable)\n\u001b[32m    908\u001b[39m                 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mrequires_grad\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[32m    909\u001b[39m                 \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[33m\"\u001b[39m\u001b[33mrequires_grad\u001b[39m\u001b[33m\"\u001b[39m].as_python_constant()\n\u001b[32m    910\u001b[39m             ):\n\u001b[32m    911\u001b[39m                 unimplemented(\n\u001b[32m    912\u001b[39m \u001b[38;5;250m                    \u001b[39m\u001b[33;03m\"\"\"factory functions that return tensors that require grad are not supported.\u001b[39;00m\n\u001b[32m    913\u001b[39m \u001b[33;03mEither create the tensor outside the compiled region, or do not set the tensor to require_grad\"\"\"\u001b[39;00m\n\u001b[32m    914\u001b[39m                 )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2037\u001b[39m, in \u001b[36mwrap_fx_proxy\u001b[39m\u001b[34m(tx, proxy, example_value, subclass_type, **options)\u001b[39m\n\u001b[32m   2029\u001b[39m kwargs = {\n\u001b[32m   2030\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtx\u001b[39m\u001b[33m\"\u001b[39m: tx,\n\u001b[32m   2031\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproxy\u001b[39m\u001b[33m\"\u001b[39m: proxy,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2034\u001b[39m     **options,\n\u001b[32m   2035\u001b[39m }\n\u001b[32m   2036\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m subclass_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_fx_proxy_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTensorVariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2039\u001b[39m     result = wrap_fx_proxy_cls(target_cls=TensorWithTFOverrideVariable, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2124\u001b[39m, in \u001b[36mwrap_fx_proxy_cls\u001b[39m\u001b[34m(target_cls, tx, proxy, example_value, subclass_type, **options)\u001b[39m\n\u001b[32m   2119\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch._dynamo.utils._disable_saved_tensors_hooks_during_tracing():\n\u001b[32m   2120\u001b[39m     \u001b[38;5;66;03m# with preserve_rng_state():\u001b[39;00m\n\u001b[32m   2121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m example_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2122\u001b[39m         \u001b[38;5;66;03m# only allow_non_graph_fake in this instance because we handle the non-fake\u001b[39;00m\n\u001b[32m   2123\u001b[39m         \u001b[38;5;66;03m# cases properly below.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2124\u001b[39m         example_value = \u001b[43mget_fake_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_non_graph_fake\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2126\u001b[39m     \u001b[38;5;66;03m# Handle recursive calls here\u001b[39;00m\n\u001b[32m   2127\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m maybe_get_fake_mode(example_value) \u001b[38;5;129;01mis\u001b[39;00m tx.fake_mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/utils.py:2082\u001b[39m, in \u001b[36mget_fake_value\u001b[39m\u001b[34m(node, tx, allow_non_graph_fake)\u001b[39m\n\u001b[32m   2079\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cause, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33margument\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(cause):\n\u001b[32m   2080\u001b[39m         unimplemented(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTypeError \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode.target\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcause\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2082\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TorchRuntimeError(\u001b[38;5;28mstr\u001b[39m(e)).with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2084\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_non_graph_fake:\n\u001b[32m   2085\u001b[39m     _ = pytree.tree_map_only(\n\u001b[32m   2086\u001b[39m         torch.Tensor, functools.partial(ensure_graph_fake, tx=tx), ret_val\n\u001b[32m   2087\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/utils.py:2017\u001b[39m, in \u001b[36mget_fake_value\u001b[39m\u001b[34m(node, tx, allow_non_graph_fake)\u001b[39m\n\u001b[32m   2015\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2016\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tx.fake_mode, enable_python_dispatcher():\n\u001b[32m-> \u001b[39m\u001b[32m2017\u001b[39m         ret_val = \u001b[43mwrap_fake_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2018\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2019\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n\u001b[32m   2021\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/utils.py:1574\u001b[39m, in \u001b[36mwrap_fake_exception\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m   1572\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_fake_exception\u001b[39m(fn):\n\u001b[32m   1573\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1574\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1575\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m UnsupportedFakeTensorException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1576\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unimplemented\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/utils.py:2018\u001b[39m, in \u001b[36mget_fake_value.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   2015\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2016\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tx.fake_mode, enable_python_dispatcher():\n\u001b[32m   2017\u001b[39m         ret_val = wrap_fake_exception(\n\u001b[32m-> \u001b[39m\u001b[32m2018\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2019\u001b[39m         )\n\u001b[32m   2020\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n\u001b[32m   2021\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/utils.py:2150\u001b[39m, in \u001b[36mrun_node\u001b[39m\u001b[34m(tracer, node, args, kwargs, nnmodule)\u001b[39m\n\u001b[32m   2148\u001b[39m         unimplemented(make_error_message(e), from_exc=e)\n\u001b[32m   2149\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2150\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(make_error_message(e)).with_traceback(\n\u001b[32m   2151\u001b[39m             e.__traceback__\n\u001b[32m   2152\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2154\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(op)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_dynamo/utils.py:2132\u001b[39m, in \u001b[36mrun_node\u001b[39m\u001b[34m(tracer, node, args, kwargs, nnmodule)\u001b[39m\n\u001b[32m   2130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2131\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m op == \u001b[33m\"\u001b[39m\u001b[33mcall_function\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2132\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2133\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m op == \u001b[33m\"\u001b[39m\u001b[33mcall_method\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2134\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(args[\u001b[32m0\u001b[39m], node.target)(*args[\u001b[32m1\u001b[39m:], **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/utils/_stats.py:21\u001b[39m, in \u001b[36mcount.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m     simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m     20\u001b[39m simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] = simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1238\u001b[39m, in \u001b[36mFakeTensorMode.__torch_dispatch__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   1235\u001b[39m     torch._C._get_dispatch_mode(torch._C._TorchDispatchModeKey.FAKE) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1236\u001b[39m ), func\n\u001b[32m   1237\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1240\u001b[39m     log.exception(\u001b[33m\"\u001b[39m\u001b[33mfake tensor raised TypeError\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1692\u001b[39m, in \u001b[36mFakeTensorMode.dispatch\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1689\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache_enabled:\n\u001b[32m-> \u001b[39m\u001b[32m1692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cached_dispatch_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_impl(func, types, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1339\u001b[39m, in \u001b[36mFakeTensorMode._cached_dispatch_impl\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1338\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_cache_key(func, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1339\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1340\u001b[39m     entry = \u001b[38;5;28mself\u001b[39m._make_cache_entry(state, key, func, args, kwargs, output)\n\u001b[32m   1341\u001b[39m     key.strip_shape_env()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1943\u001b[39m, in \u001b[36mFakeTensorMode._dispatch_impl\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1933\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m decomposition_table \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m   1934\u001b[39m     has_symbolic_sizes\n\u001b[32m   1935\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1940\u001b[39m     )\n\u001b[32m   1941\u001b[39m ):\n\u001b[32m   1942\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1943\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecomposition_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m   1946\u001b[39m     \u001b[38;5;66;03m# Decomposes CompositeImplicitAutograd ops\u001b[39;00m\n\u001b[32m   1947\u001b[39m     r = func.decompose(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:273\u001b[39m, in \u001b[36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[39m\u001b[34m(out, *args, **kwargs)\u001b[39m\n\u001b[32m    271\u001b[39m     result = fn(*args, is_out=(out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), **kwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    275\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(result, TensorLike)\n\u001b[32m    276\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m is_tensor\n\u001b[32m    277\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Tuple)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    278\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) == \u001b[38;5;28mlen\u001b[39m(out_names)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    279\u001b[39m )\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# Naively you might expect this assert to be true, but\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;66;03m# it's not:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m     \u001b[38;5;66;03m# be a normal meta tensor, but this is perfectly\u001b[39;00m\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# harmless.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_decomp/decompositions.py:83\u001b[39m, in \u001b[36mtype_casts.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m r = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincrease_prec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincrease_prec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compute_dtype_only:\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_decomp/decompositions.py:1515\u001b[39m, in \u001b[36maddmm\u001b[39m\u001b[34m(self, mat1, mat2, beta, alpha)\u001b[39m\n\u001b[32m   1513\u001b[39m     beta = \u001b[38;5;28mint\u001b[39m(beta)\n\u001b[32m   1514\u001b[39m     alpha = \u001b[38;5;28mint\u001b[39m(alpha)\n\u001b[32m-> \u001b[39m\u001b[32m1515\u001b[39m out = alpha * \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1516\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m beta == \u001b[32m0\u001b[39m:\n\u001b[32m   1517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/utils/_stats.py:21\u001b[39m, in \u001b[36mcount.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m     simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m     20\u001b[39m simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] = simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1238\u001b[39m, in \u001b[36mFakeTensorMode.__torch_dispatch__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   1235\u001b[39m     torch._C._get_dispatch_mode(torch._C._TorchDispatchModeKey.FAKE) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1236\u001b[39m ), func\n\u001b[32m   1237\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1240\u001b[39m     log.exception(\u001b[33m\"\u001b[39m\u001b[33mfake tensor raised TypeError\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1692\u001b[39m, in \u001b[36mFakeTensorMode.dispatch\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1689\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache_enabled:\n\u001b[32m-> \u001b[39m\u001b[32m1692\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cached_dispatch_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_impl(func, types, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1339\u001b[39m, in \u001b[36mFakeTensorMode._cached_dispatch_impl\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1338\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_cache_key(func, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1339\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1340\u001b[39m     entry = \u001b[38;5;28mself\u001b[39m._make_cache_entry(state, key, func, args, kwargs, output)\n\u001b[32m   1341\u001b[39m     key.strip_shape_env()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2013\u001b[39m, in \u001b[36mFakeTensorMode._dispatch_impl\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   2011\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2012\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m in_kernel_invocation_manager(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2013\u001b[39m         r = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2014\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m not_implemented_error:\n\u001b[32m   2015\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m maybe_run_unsafe_fallback(not_implemented_error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_ops.py:716\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_prims_common/wrappers.py:273\u001b[39m, in \u001b[36mout_wrapper.<locals>._out_wrapper.<locals>._fn\u001b[39m\u001b[34m(out, *args, **kwargs)\u001b[39m\n\u001b[32m    271\u001b[39m     result = fn(*args, is_out=(out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), **kwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    275\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(result, TensorLike)\n\u001b[32m    276\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m is_tensor\n\u001b[32m    277\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Tuple)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    278\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) == \u001b[38;5;28mlen\u001b[39m(out_names)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    279\u001b[39m )\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# Naively you might expect this assert to be true, but\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;66;03m# it's not:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m     \u001b[38;5;66;03m# be a normal meta tensor, but this is perfectly\u001b[39;00m\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# harmless.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/_meta_registrations.py:2100\u001b[39m, in \u001b[36mmeta_mm\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m   2098\u001b[39m N, M1 = a.shape\n\u001b[32m   2099\u001b[39m M2, P = b.shape\n\u001b[32m-> \u001b[39m\u001b[32m2100\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mM1\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mM2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2102\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma and b must have same reduction dim, but got [\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mN\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mM1\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m] X [\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mM2\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m, \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mP\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m].\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m a.new_empty(N, P)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/__init__.py:1564\u001b[39m, in \u001b[36m_check\u001b[39m\u001b[34m(cond, message)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check\u001b[39m(cond, message=\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   1550\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Throws error containing an optional message if the specified condition\u001b[39;00m\n\u001b[32m   1551\u001b[39m \u001b[33;03m    is False.\u001b[39;00m\n\u001b[32m   1552\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1562\u001b[39m \u001b[33;03m            message. Default: ``None``\u001b[39;00m\n\u001b[32m   1563\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1564\u001b[39m     \u001b[43m_check_with\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/__init__.py:1546\u001b[39m, in \u001b[36m_check_with\u001b[39m\u001b[34m(error_type, cond, message)\u001b[39m\n\u001b[32m   1542\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmessage must be a callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1544\u001b[39m     message_evaluated = \u001b[38;5;28mstr\u001b[39m(message())\n\u001b[32m-> \u001b[39m\u001b[32m1546\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error_type(message_evaluated)\n",
      "\u001b[31mTorchRuntimeError\u001b[39m: Failed running call_function <built-in function linear>(*(FakeTensor(..., device='cuda:0', size=(512, 21)), Parameter(FakeTensor(..., device='cuda:0', size=(1024, 20), requires_grad=True)), Parameter(FakeTensor(..., device='cuda:0', size=(1024,), requires_grad=True))), **{}):\na and b must have same reduction dim, but got [512, 21] X [20, 1024].\n\nfrom user code:\n   File \"/orcd/home/002/corte911/code/finNN_code/src/models/mlp.py\", line 82, in forward\n    return self.net(x)\n  File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 250, in forward\n    input = module(input)\n  File \"/home/corte911/.conda/envs/torch_h200_py312/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n    return F.linear(input, self.weight, self.bias)\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# instantiate trainer (PyTorch)\n",
    "#trainer = Trainer(cfg, logger)\n",
    "\n",
    "# model input size: number of lags (columns are constant across folds)\n",
    "input_shape = cfg.walkforward.lags            # int is fine; build_model handles it\n",
    "max_folds = cfg.walkforward.max_folds\n",
    "\n",
    "if cfg.model.name.lower() == \"cnn1d\":\n",
    "    input_shape = (1, cfg.walkforward.lags)  # (C, L)\n",
    "elif cfg.model.name.lower() == \"mlp\":\n",
    "    input_shape = (cfg.walkforward.lags,)\n",
    "else:\n",
    "    console_logger.warning(f\"Model: {cfg.model.name} not recognized!\")\n",
    "\n",
    "def make_input_shape(c):\n",
    "    if cfg.model.name.lower() == \"mlp\":\n",
    "        return (c.walkforward.lags, )\n",
    "    elif cfg.model.name.lower() == \"cnn1d\":\n",
    "        return (1, cfg.walkforward.lags)  # (C, L)\n",
    "    else:\n",
    "        console_logger.warning(f\"Model: {cfg.model.name} not recognized!\")\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "\n",
    "# Get bool for search\n",
    "hyperparams_search = cfg.experiment.hyperparams_search\n",
    "\n",
    "if not hyperparams_search:\n",
    "    console_logger.warning(\"No hyperparams search for this experiment\")\n",
    "    logger = ExperimentLogger(cfg) \n",
    "    trainer = Trainer(cfg, logger)\n",
    "    logger.begin_trial()\n",
    "\n",
    "# -------- train per fold --------\n",
    "for fold, data in enumerate(wf.folds()):\n",
    "    if max_folds is not None and fold >= max_folds:\n",
    "        break  # allow running subset of folds\n",
    "    else:\n",
    "        # Keep model creation inside the loop to avoid weight leakage across folds\n",
    "        # Keep model creation inside the loop to avoid weight leakage across folds\n",
    "        model = create_model(cfg.model, input_shape)       \n",
    "\n",
    "        if fold == 0:\n",
    "            console_logger.debug(f\"model: {model}\")\n",
    "\n",
    "        trainer.fit_eval_fold(model, data, trial=0, fold=fold)\n",
    "\n",
    "console_logger.warning(\"Training completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799bf3d3",
   "metadata": {},
   "source": [
    "test con giuseppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba11f38c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "adjust_for_splits() got an unexpected keyword argument 'base_cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m cfg = AppConfig.from_dict(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/debug.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m wf = \u001b[43mWFCVGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwalkforward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m df = wf.df_master\n\u001b[32m      5\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/corte911/code/finNN_code/src/pipeline/walkforward.py:35\u001b[39m, in \u001b[36mWFCVGenerator.__init__\u001b[39m\u001b[34m(self, config, id_col, df_long, time_col, value_cols, target_col, scaler_factory)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# build wide dict once (cheap, readable)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_long.size == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28mself\u001b[39m.df = \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[[\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mret\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpermno\u001b[39m\u001b[33m\"\u001b[39m]].copy()\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# define number of trading days\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;28mself\u001b[39m.T = \u001b[38;5;28mself\u001b[39m.df[\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m].nunique()    \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/corte911/code/finNN_code/src/pipeline/preprocessing.py:3\u001b[39m, in \u001b[36mpreprocess\u001b[39m\u001b[34m(ohlc_rets)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterable\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpaths\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SP500_PATH\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimport_data\u001b[39m(path) -> pd.DataFrame:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/orcd/home/002/corte911/code/finNN_code/src/pipeline/preprocessing.py:41\u001b[39m, in \u001b[36mhandle_nans\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madjust_for_splits\u001b[39m(\n\u001b[32m     19\u001b[39m     df: pd.DataFrame,\n\u001b[32m     20\u001b[39m     price_cols: Iterable[\u001b[38;5;28mstr\u001b[39m] = (\u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mopen\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     group_col: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mpermno\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m ) -> pd.DataFrame:\n\u001b[32m     26\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m    Split/Share adjustments using CRSP cumulative factors.\u001b[39;00m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33;03m    Prices:     adjusted = raw / cfacpr\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[33;03m    Volume-like adjusted = raw * cfacshr\u001b[39;00m\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[33;03m    - Returns columns ('ret' or 'ret_*') are NEVER modified.\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    - Missing factors default to 1.0 after forward-fill within each permno.\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[33;03m    - Columns not present are silently skipped.\u001b[39;00m\n\u001b[32m     35\u001b[39m \n\u001b[32m     36\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33;03m    ----------\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33;03m    df : DataFrame\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    price_cols : columns to treat as prices (divide by cfacpr)\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    vol_cols   : columns to treat as volume/shares (multiply by cfacshr)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[33;03m    price_factor : name of cumulative price factor (cfacpr)\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    share_factor : name of cumulative share factor (cfacshr)\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m    group_col    : security identifier (permno)\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m     out = df.copy()\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m group_col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out.columns:\n",
      "\u001b[31mTypeError\u001b[39m: adjust_for_splits() got an unexpected keyword argument 'base_cols'"
     ]
    }
   ],
   "source": [
    "cfg = AppConfig.from_dict(f\"{CONFIG_DIR}/debug.yaml\")\n",
    "wf = WFCVGenerator(config=cfg.walkforward)\n",
    "\n",
    "df = wf.df_master\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb4aaf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['window'], inplace=True)\n",
    "df['y'] = df['y'].apply(lambda x: 1 if x >= 0 else 0 if x < 0 else 0)\n",
    "train_data = df.iloc[:100000].copy()\n",
    "test_data = df.iloc[100001:150000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "418e2509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.7321\n",
      "Epoch [20/50], Loss: 0.6714\n",
      "Epoch [30/50], Loss: 0.7076\n",
      "Epoch [40/50], Loss: 0.7103\n",
      "Epoch [50/50], Loss: 0.6012\n",
      "Training finished.\n",
      "Test MSE Loss: 0.7432\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "Prediction: 0.24, Actual: 0.00\n",
      "Prediction: -0.09, Actual: 1.00\n",
      "Prediction: -0.40, Actual: 1.00\n",
      "Prediction: -0.65, Actual: 1.00\n",
      "Prediction: 0.50, Actual: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cfg = AppConfig.from_dict(f\"{CONFIG_DIR}/debug.yaml\")\n",
    "wf = WFCVGenerator(config=cfg.walkforward)\n",
    "\n",
    "train_df = train_data\n",
    "test_df = test_data\n",
    "\n",
    "X_train_df = train_df.drop('y', axis=1)\n",
    "y_train_df = train_df['y']\n",
    "X_test_df = test_df.drop('y', axis=1)\n",
    "y_test_df = test_df['y']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_df)\n",
    "X_test_scaled = scaler.transform(X_test_df)\n",
    "\n",
    "# Convert to PyTorch Tensors\n",
    "X_train = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_df.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test_df.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# --- 3. Define the Neural Network ---\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# --- 4. Training ---\n",
    "# Instantiate the model\n",
    "input_features = X_train.shape[1]\n",
    "model = SimpleNet(input_size=input_features)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# --- 5. Evaluation ---\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # No need to track gradients for evaluation\n",
    "    predictions = model(X_test)\n",
    "    test_loss = criterion(predictions, y_test)\n",
    "    print(f'Test MSE Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# You can inspect some predictions\n",
    "print(\"\\nSample Predictions vs Actuals:\")\n",
    "for i in range(5):\n",
    "    print(f\"Prediction: {predictions[i].item():.2f}, Actual: {y_test[i].item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e8129b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [10/50], Loss: 0.0011\n",
      "Epoch [20/50], Loss: 0.0004\n",
      "Epoch [30/50], Loss: 0.0009\n",
      "Epoch [40/50], Loss: 0.0007\n",
      "Epoch [50/50], Loss: 0.0019\n",
      "Training finished.\n",
      "Test MSE Loss: 0.0015\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "Prediction: 0.00, Actual: -0.04\n",
      "Prediction: 0.00, Actual: 0.03\n",
      "Prediction: 0.00, Actual: 0.02\n",
      "Prediction: 0.00, Actual: 0.01\n",
      "Prediction: 0.00, Actual: 0.05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "gpu_test()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_df.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test_df.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_train = X_train_tensor.unsqueeze(1)\n",
    "X_test = X_test_tensor.unsqueeze(1)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# --- 3. Define the CNN ---\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input shape: (batch_size, 1, num_features)\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        # The size of the flattened layer will be out_channels * num_features\n",
    "        self.fc1 = nn.Linear(16 * num_features, 32)\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 1, num_features)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # x shape: (batch_size, 16, num_features)\n",
    "        x = self.flatten(x)\n",
    "        # x shape: (batch_size, 16 * num_features)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# --- 4. Training ---\n",
    "# Instantiate the model\n",
    "input_features = X_train.shape[2] # Number of features is the last dimension\n",
    "model = SimpleCNN(num_features=input_features)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "# --- 5. Evaluation ---\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    test_loss = criterion(predictions, y_test)\n",
    "    print(f'Test MSE Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# You can inspect some predictions\n",
    "print(\"\\nSample Predictions vs Actuals:\")\n",
    "for i in range(5):\n",
    "    print(f\"Prediction: {predictions[i].item():.2f}, Actual: {y_test[i].item():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
