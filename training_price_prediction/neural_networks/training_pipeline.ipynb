{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b73780b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4123a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 20:33:30.311793: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-10 20:33:30.348221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-10 20:33:31.482645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaff41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.walkforward import  WFCVTrainer, WFConfig\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "config = WFConfig\n",
    "wfcv = WFCVTrainer(config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48d14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, \n",
    "                         n_hidden_layers=2, \n",
    "                         n_neurons=32, \n",
    "                         dropout_rate=0.2, \n",
    "                         activation='relu',\n",
    "                         l2_reg=0.001,\n",
    "                         learning_rate=0.001):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Input(shape=(input_shape,)))\n",
    "    \n",
    "    for i in range(n_hidden_layers):\n",
    "        model.add(layers.Dense(\n",
    "            n_neurons, \n",
    "            activation=activation,\n",
    "            kernel_regularizer=l2(l2_reg) \n",
    "        ))\n",
    "        if dropout_rate > 0:\n",
    "            model.add(layers.Dropout(dropout_rate))\n",
    "            \n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d109d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Fold 0 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning hyperparameters for Fold 0 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 20:34:46.321784: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m learning_rate \u001b[38;5;129;01min\u001b[39;00m param_grid[\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     29\u001b[39m     model = build_model(\n\u001b[32m     30\u001b[39m         input_shape=X_train.shape[\u001b[32m1\u001b[39m],\n\u001b[32m     31\u001b[39m         n_neurons=n_neurons,\n\u001b[32m     32\u001b[39m         learning_rate=learning_rate\n\u001b[32m     33\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     val_mse = model.evaluate(X_val, y_val, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val_mse < best_val_mse:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    130\u001b[39m args = args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[32m    131\u001b[39m kwargs = kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m function = \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[39m, in \u001b[36mtrace_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    175\u001b[39m     args = tracing_options.input_signature\n\u001b[32m    176\u001b[39m     kwargs = {}\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m   concrete_function = \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options.bind_graph_to_function:\n\u001b[32m    183\u001b[39m   concrete_function._garbage_collector.release()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[39m, in \u001b[36m_maybe_define_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    229\u001b[39m lookup_func_type, lookup_func_context = (\n\u001b[32m    230\u001b[39m     function_type_utils.make_canonicalized_monomorphic_type(\n\u001b[32m    231\u001b[39m         args,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m     )\n\u001b[32m    236\u001b[39m )\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracing_options.function_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m   concrete_function = \u001b[43mtracing_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunction_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    243\u001b[39m   concrete_function = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[39m, in \u001b[36mFunctionCache.lookup\u001b[39m\u001b[34m(self, function_type, context)\u001b[39m\n\u001b[32m     46\u001b[39m context = context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_dict:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m   dispatch_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._primary[(context, dispatch_type)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:85\u001b[39m, in \u001b[36mTypeDispatchTable.dispatch\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     81\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m request\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# For known non-exact matches.\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# (self._dispatch cache does not contain exact matches)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_cache\u001b[49m:\n\u001b[32m     86\u001b[39m   \u001b[38;5;66;03m# Move to the front of LRU cache.\u001b[39;00m\n\u001b[32m     87\u001b[39m   result = \u001b[38;5;28mself\u001b[39m._dispatch_cache.pop(request)\n\u001b[32m     88\u001b[39m   \u001b[38;5;28mself\u001b[39m._dispatch_cache[request] = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:452\u001b[39m, in \u001b[36mFunctionType.__eq__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, FunctionType):\n\u001b[32m    450\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m, \u001b[38;5;28mself\u001b[39m.captures) == (other.parameters,\n\u001b[32m    453\u001b[39m                                             other.captures)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jupyter_env/lib/python3.12/site-packages/tensorflow/core/function/polymorphism/function_type.py:195\u001b[39m, in \u001b[36mFunctionType.parameters\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    192\u001b[39m   \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(parameters, **kwargs)\n\u001b[32m    193\u001b[39m   \u001b[38;5;28mself\u001b[39m._captures = captures \u001b[38;5;28;01mif\u001b[39;00m captures \u001b[38;5;28;01melse\u001b[39;00m collections.OrderedDict()\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    197\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns an ordered mapping of parameter name to specification.\"\"\"\u001b[39;00m\n\u001b[32m    198\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().parameters\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_fold_results = []\n",
    "\n",
    "param_grid = {\n",
    "    'n_hidden_layers': [1, 2, 3],\n",
    "    'n_neurons': [16, 32, 64],\n",
    "    'dropout_rate': [0.0, 0.2, 0.5],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'l2_reg': [0.0, 0.001, 0.01],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001]\n",
    "}\n",
    "\n",
    "for fold in range(config.folds):\n",
    "\n",
    "    print(f\"\\n===== Processing Fold {fold} =====\")\n",
    "    \n",
    "    df_train, df_val, df_test = wfcv.obtain_datasets_fold(fold)\n",
    "\n",
    "    X_train = df_train.drop(['y'], axis=1).values\n",
    "    y_train = df_train['y'].values\n",
    "    X_val = df_val.drop(['y'], axis=1).values\n",
    "    y_val = df_val['y'].values\n",
    "\n",
    "    best_val_mse = float('inf')\n",
    "    best_params = None\n",
    "    \n",
    "    print(f\"--- Tuning hyperparameters for Fold {fold} ---\")\n",
    "    for n_neurons in param_grid['n_neurons']:\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            model = build_model(\n",
    "                input_shape=X_train.shape[1],\n",
    "                n_neurons=n_neurons,\n",
    "                learning_rate=learning_rate\n",
    "            )\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=50, \n",
    "                batch_size=32,\n",
    "                verbose=0 \n",
    "            )\n",
    "            \n",
    "            val_mse = model.evaluate(X_val, y_val, verbose=0)\n",
    "            \n",
    "            if val_mse < best_val_mse:\n",
    "                best_val_mse = val_mse\n",
    "                best_params = {'n_neurons': n_neurons, 'learning_rate': learning_rate}\n",
    "\n",
    "    print(f\"Best hyperparameters found: {best_params}\")\n",
    "\n",
    "    print(f\"--- Refitting model on combined training & validation data for Fold {fold} ---\")\n",
    "    \n",
    "    full_train_df = pd.concat([df_train, df_val])\n",
    "    X_full_train = full_train_df.drop(['y'], axis=1).values\n",
    "    y_full_train = full_train_df['y'].values\n",
    "    \n",
    "    X_test = df_test.drop(['y'], axis=1).values\n",
    "    y_test = df_test['y'].values\n",
    "    \n",
    "    final_model = build_model(\n",
    "        input_shape=X_full_train.shape[1],\n",
    "        **best_params\n",
    "    )\n",
    "    final_model.fit(\n",
    "        X_full_train, y_full_train,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    mse_in_sample = final_model.evaluate(X_full_train, y_full_train, verbose=0)\n",
    "    rmse_in_sample = np.sqrt(mse_in_sample)\n",
    "    y_pred_in_sample = final_model.predict(X_full_train, verbose=0).flatten()\n",
    "    dir_acc_in_sample = np.mean(np.sign(y_pred_in_sample) == np.sign(y_full_train)) * 100\n",
    "\n",
    "    mse_out_of_sample = final_model.evaluate(X_test, y_test, verbose=0)\n",
    "    rmse_out_of_sample = np.sqrt(mse_out_of_sample)\n",
    "    y_pred_out_of_sample = final_model.predict(X_test, verbose=0).flatten()\n",
    "    dir_acc_out_of_sample = np.mean(np.sign(y_pred_out_of_sample) == np.sign(y_test)) * 100\n",
    "    \n",
    "    print(f\"In-sample RMSE: {rmse_in_sample:.6f} | In-sample Directional Accuracy: {dir_acc_in_sample:.2f}%\")\n",
    "    print(f\"Out-of-sample RMSE: {rmse_out_of_sample:.6f} | Out-of-sample Directional Accuracy: {dir_acc_out_of_sample:.2f}%\")\n",
    "\n",
    "    model_path = f'models/model_fold_{fold}.keras'\n",
    "    final_model.save(model_path)\n",
    "    \n",
    "    fold_results = {\n",
    "        'fold': fold,\n",
    "        'best_hyperparameters': best_params,\n",
    "        'in_sample_rmse': rmse_in_sample,\n",
    "        'out_of_sample_rmse': rmse_out_of_sample,\n",
    "        'in_sample_dir_acc': dir_acc_in_sample,\n",
    "        'out_of_sample_dir_acc': dir_acc_out_of_sample,\n",
    "        'model_path': model_path\n",
    "    }\n",
    "    all_fold_results.append(fold_results)\n",
    "\n",
    "results_df = pd.DataFrame(all_fold_results)\n",
    "results_df.to_csv('model_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
